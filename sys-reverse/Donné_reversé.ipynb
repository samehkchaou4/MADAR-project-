{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer , CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import Pipeline\n",
    "#recupération des données\n",
    "TRAIN_SET_PATH = \"/media/sameh/data/france/madar_shared_task/MADAR-Shared-Task-Subtask-1/MADAR-Corpus-26-train.txt\"\n",
    "import pandas as pd\n",
    "\n",
    "with open(TRAIN_SET_PATH, \"r\", encoding='utf_8') as infile:\n",
    "    X, y = [], []\n",
    "    for line in infile:\n",
    "        text, label  = line.split(\"\\t\")\n",
    "        X.append(text)\n",
    "        y.append(label)\n",
    "data = {'phrase':X,'label':y}\n",
    "df= pd.DataFrame(data)\n",
    "#pretraitement des données \n",
    "import re \n",
    "arabic_diacritics = re.compile(\"\"\"\n",
    "                             ّ    | \n",
    "                             َ    | \n",
    "                             ً    | \n",
    "                             ُ    | \n",
    "                             ٌ    | \n",
    "                             ِ    | \n",
    "                             ٍ    | \n",
    "                             ْ    | \n",
    "                             ـ     \n",
    "                         \"\"\", re.VERBOSE)\n",
    "arabic_punctuations = '''`÷×؛<>_()*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ'''\n",
    "listtrain=[]\n",
    "#supprime les diactritics \n",
    "def remove_diacritics(text):\n",
    "    text = re.sub(arabic_diacritics, '', text)\n",
    "    return text\n",
    "#supprime les signes des ponctuations \n",
    "def remove_punctuations(text):\n",
    "    translator = str.maketrans('', '', arabic_punctuations)\n",
    "    return text.translate(translator)\n",
    "#Supprimer les nombres \n",
    "def remove_numbers(text):\n",
    "    regex = re.compile(r\"(\\d|[\\u0660\\u0661\\u0662\\u0663\\u0664\\u0665\\u0666\\u0667\\u0668\\u0669])+\")\n",
    "    return re.sub(regex, ' ', text)\n",
    "#supprimer les noms non arabe \n",
    "def remove_non_arabic_words(text):\n",
    "    return ' '.join([word for word in text.split() if not re.findall(\n",
    "        r'[^\\s\\u0621\\u0622\\u0623\\u0624\\u0625\\u0626\\u0627\\u0628\\u0629\\u062A\\u062B\\u062C\\u062D\\u062E\\u062F\\u0630\\u0631\\u0632\\u0633\\u0634\\u0635\\u0636\\u0637\\u0638\\u0639\\u063A\\u0640\\u0641\\u0642\\u0643\\u0644\\u0645\\u0646\\u0647\\u0648\\u0649\\u064A]',\n",
    "        word)])\n",
    "import tashaphyne ,sys \n",
    "import tashaphyne.arabic_const as arabcons\n",
    "def strip_tashkeel(text): \n",
    "    return tashaphyne.arabic_const.HARAKAT_PAT.sub('', text) \n",
    "def strip_tatweel(text): \n",
    "    return re.sub(tashaphyne.arabic_const.TATWEEL, '', text) \n",
    "def normalize_hamza(text):\n",
    "    text = tashaphyne.arabic_const.ALEFAT_PAT.sub(tashaphyne.arabic_const.ALEF, text) \n",
    "    return tashaphyne.arabic_const.HAMZAT_PAT.sub(tashaphyne.arabic_const.HAMZA, text) \n",
    "def normalize_lamalef(text):\n",
    "    return tashaphyne.arabic_const.LAMALEFAT_PAT.sub(\\\n",
    "                                       u'%s%s'%(tashaphyne.arabic_const.LAM, tashaphyne.arabic_const.ALEF), text) \n",
    "def normalize_spellerrors(text): \n",
    "    text = re.sub(tashaphyne.arabic_const.TEH_MARBUTA,tashaphyne.arabic_const.HEH, text) \n",
    "    return re.sub(tashaphyne.arabic_const.ALEF_MAKSURA,tashaphyne.arabic_const.YEH, text)\n",
    "\n",
    "train = list(df['phrase'])\n",
    "for data in train:\n",
    "    data = normalize_spellerrors(data)\n",
    "    data = normalize_lamalef(data)\n",
    "    data = normalize_hamza(data)\n",
    "    data = strip_tashkeel(data)\n",
    "    data = strip_tatweel(data)\n",
    "    data = remove_diacritics(data)\n",
    "    data = remove_punctuations(data)\n",
    "    data = remove_numbers(data)\n",
    "    data = remove_non_arabic_words(data)\n",
    "    listtrain.append(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تلمع كيهو\n"
     ]
    }
   ],
   "source": [
    "#reverser les données récupérée \n",
    "#définir champ \"step\" sous la forme [start, stop, step] et ne donner aucun champ au début et à la fin, indique par défaut 0 et la longueur de la chaîne, et \" -1 \" indique un début et une fin à la fin. \n",
    "def reversed_string(a_string):\n",
    "    return a_string[::-1]\n",
    "print(reversed_string('وهيك عملت'))\n",
    "listrev=[]\n",
    "for i in listtrain :\n",
    "    listrev.append(reversed_string(i))\n",
    "df['phrase']= listrev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kenlm , math, glob \n",
    "import os,sys\n",
    "import pandas as pd\n",
    "class TextStats(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        res=[{'score': x[0],'model':x[1]} \n",
    "            for x in X[[ 'score','model']].values]\n",
    "        return res\n",
    "    \n",
    "class ItemSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data_dict):\n",
    "        return data_dict[self.key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41600, 4)\n"
     ]
    }
   ],
   "source": [
    "import kenlm , math, glob \n",
    "import os,sys\n",
    "import pandas as pd\n",
    "# function qui return la meilleur score+ le nom d model \n",
    "corp = ['ale-char', 'asw-char', 'msa-char', 'sal-char', 'jed-char', 'bag-char', 'san-char', 'kha-char', 'rab-char', 'mus-char', 'jer-char', 'bas-char', 'tri-char', 'alg-char', 'riy-char', 'amm-char', 'tun-char', 'fes-char', 'ben-char', 'alx-char', 'sfx-char', 'dam-char', 'bei-char', 'cai-char', 'mos-char', 'doh-char']\n",
    "#modification par medellm reverse\n",
    "def scoremodel(s):\n",
    "    m = list(map(lambda code: kenlm.LanguageModel('/media/sameh/data/CORPUS/LM-corpus/model-lm-reverse/' + code + \".binary\"), corp))\n",
    "\n",
    "    s = ' '.join('#'.join(s.split()))\n",
    "    maxl = ''\n",
    "    maxp =  -sys.maxsize + 1 #minimum integer in python\n",
    "    totalp = 0.0\n",
    "    for j in range(len(m)):\n",
    "        model = m[j]\n",
    "        prob = model.score(s)\n",
    "        totalp += math.pow(10.0, prob)\n",
    "        if(prob > maxp):\n",
    "            maxp = prob\n",
    "            maxl = corp[j]\n",
    "    #if else yetna7aw et round to proba sera dans boucle for pui l'ajout dans liste  \n",
    "    if(totalp==0.0): prob = 0.0\n",
    "    else: prob = math.pow(10.0,maxp)/totalp\n",
    "    #round to thousandths\n",
    "    prob = math.floor(1000*prob)/1000\n",
    "    tupler=(maxl,prob)\n",
    "    return tupler       \n",
    "#ajouter au df 2 column pour score et label du model par phrase\n",
    "listscoreph=[ ]\n",
    "listmodelph=[ ]\n",
    "for i in list(df['phrase']):\n",
    "    listscoreph.append(scoremodel(i)[1])\n",
    "    listmodelph.append(scoremodel(i)[0])\n",
    "df['score'] = listscoreph\n",
    "df['model'] = listmodelph\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('features', FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('feature1', Pipeline(memory=None,\n",
       "     steps=[('selector', ItemSelector(key='phrase')), ('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', inp...ansformer_weights=None)), ('clasifier', MultinomialNB(alpha=0.5, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "def stemming_tokenizer(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    return [stemmer.stem(w) for w in word_tokenize(text)]\n",
    "pipeline = Pipeline([\n",
    "\n",
    "      ('features', FeatureUnion(\n",
    "           transformer_list =[\n",
    "       ('feature1', Pipeline([\n",
    "                    ('selector', ItemSelector(key='phrase')),\n",
    "                    ('tfidf', TfidfVectorizer(tokenizer=stemming_tokenizer,analyzer='word',ngram_range=(1,1))),\n",
    "        ])),\n",
    "       ('feature2', Pipeline([\n",
    "                    ('stats',TextStats()), \n",
    "                    ('vect', DictVectorizer())\n",
    "       ]))     \n",
    "           ]\n",
    ")),\n",
    "    ('clasifier', MultinomialNB(alpha=0.5,fit_prior=True, class_prior=None)),\n",
    "                 ])\n",
    "\n",
    "pipeline.fit(df, df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5200, 4)\n"
     ]
    }
   ],
   "source": [
    "TRAIN_SET_PATH = \"/media/sameh/data/france/madar_shared_task/MADAR-Shared-Task-Subtask-1/MADAR-Corpus-26-dev.tsv\"\n",
    "with open(TRAIN_SET_PATH, \"r\", encoding='utf_8') as infile:\n",
    "    xt,yt = [],[]\n",
    "    for line in infile:\n",
    "        text, label  = line.split(\"\\t\")\n",
    "        xt.append(text)\n",
    "        yt.append(label)\n",
    "#recupére donée de test dans data frame \n",
    "datatest = {'phrase':xt,'label':yt}\n",
    "dfdev= pd.DataFrame(datatest)\n",
    "#recupérer les phrasees pour prétraitement\n",
    "test = list(dfdev['phrase'])\n",
    "listtest=[]\n",
    "for data in test:\n",
    "    data = normalize_spellerrors(data)\n",
    "    data = normalize_lamalef(data)\n",
    "    data = normalize_hamza(data)\n",
    "    data = strip_tashkeel(data)\n",
    "    data = strip_tatweel(data)\n",
    "    data = remove_diacritics(data)\n",
    "    data = remove_punctuations(data)\n",
    "    data = remove_numbers(data)\n",
    "    data = remove_non_arabic_words(data)\n",
    "    listtest.append(data)\n",
    "#inverser les données prétraité pour l'ajouter dans dataframe de dev   \n",
    "listdevrev=[]\n",
    "for i in listtest :\n",
    "    listdevrev.append(reversed_string(i))\n",
    "dfdev['phrase']= listdevrev\n",
    "#ajouter au df 2 column pour score et label du model par phrase\n",
    "listscoredev=[ ]\n",
    "listmodeldev=[ ]\n",
    "for i in list(dfdev['phrase']):\n",
    "    listscoredev.append(scoremodel(i)[1])\n",
    "    listmodeldev.append(scoremodel(i)[0])\n",
    "dfdev['score'] = listscoredev\n",
    "dfdev['model'] = listmodeldev\n",
    "print(dfdev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5200\n",
      "Accuracy =  0.8521153846153846\n"
     ]
    }
   ],
   "source": [
    "predicted = pipeline.predict(dfdev)\n",
    "print (len(predicted))\n",
    "print('Accuracy = ',np.mean(predicted == dfdev['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1ér test : test des données reversé par tfidfvectorizer() seul (pour word de 1 à 5 gramme) => tjr résulat ne change pas : 64.27%\n",
    "#j'ai ajoué la normalization des données comme la création des modéles reversé dans la prétraitement \n",
    "#2ém test : test de l'union des features tfidfvectorizer() + LMs reversé => dimunie de 85.35% à 85.21% \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  phrase  label  score  \\\n",
      "0                               امامت حءاسلا تانايب ماما  MSA\\n  0.999   \n",
      "1              انه نم برقلاب لبق نم ناونعلا اذهب عمسا مل  MSA\\n  0.999   \n",
      "2            هيلديص دجت يتح قيرطلا اذه يف ريسلا يف رمتسا  MSA\\n  0.999   \n",
      "3                                       راطفالا هفلكت مك  MSA\\n  0.720   \n",
      "4                                     كتدعاسم عيطتسا فيك  MSA\\n  0.982   \n",
      "5                         هثلاثلا هيصانلا دنع اراسي هجتا  MSA\\n  0.999   \n",
      "6                       كتوهق يف ركسو هدشق عضت نا بحت له  MSA\\n  0.999   \n",
      "7          يب صاخلا رالود يتءاملا وذ كيشلا فرص مكنكمي له  MSA\\n  0.999   \n",
      "8                            يب لصتا كلضف نم كلذ ثدح اذا  MSA\\n  0.999   \n",
      "9                                             يهقملا نيا  MSA\\n  0.283   \n",
      "10                                    لافطالل تيكاج ديرا  MSA\\n  0.993   \n",
      "11     صاخلا ليصوتلا يف تارالود هثالثو يداعلا ديربلا ...  MSA\\n  0.999   \n",
      "12                   مدقلا عباصا دنع يميرح هيذحا كيدل له  MSA\\n  0.999   \n",
      "13                     كرامجلا يف تابوعص هيا ينهجاوتس له  MSA\\n  0.999   \n",
      "14     هدحاو انيدل نحنف يدرفلا مادختسالل نيريرس تاذ ه...  MSA\\n  1.000   \n",
      "15                       كلضف نم يرعشل براقتم جيومت ديرا  MSA\\n  0.999   \n",
      "16                                          هريب ديرت يه  MSA\\n  0.745   \n",
      "17                                   كلاح فيك ريخلا حابص  MSA\\n  0.326   \n",
      "18     هيوهلا ديدحتل دنتسم يا يلع علطا نا يلا هجاحب ي...  MSA\\n  1.000   \n",
      "19                                     سبالملا نم عون يا  MSA\\n  0.348   \n",
      "20            هنيخستب موقت نا نكمي له ام دح يلا دراب اذه  MSA\\n  0.999   \n",
      "21          قيدصب لاصتالا يف عنامت له نكل هيدج هلاحب انا  MSA\\n  0.999   \n",
      "22                                    كل قيدص لضفا وه نم  MSA\\n  0.996   \n",
      "23     نينطاوملا هحص نيسحت اهنم ضرغلا هيموق هزاجا وهو...  MSA\\n  1.000   \n",
      "24                         هرايسلا روتوم صحفا نا ديرت له  MSA\\n  0.999   \n",
      "25                 يتبيقح يلا لوصولا يف يندعاست نا كل له  MSA\\n  0.999   \n",
      "26                         امدقم تابيترتلا لمعب موقتس له  MSA\\n  0.997   \n",
      "27                             كل اركش هدعاسملا يلا مدقت  MSA\\n  0.583   \n",
      "28                   كلضف نم رخا صخش لاسا كانه لصت امدنع  MSA\\n  0.999   \n",
      "29                     كلضف نم نورشعو عبرا دادتمالا ديرا  MSA\\n  0.999   \n",
      "...                                                  ...    ...    ...   \n",
      "41570                           ايانه نم كيسرك يل كعفرنح  TRI\\n  0.999   \n",
      "41571                               لاءس كلاسن ردقن اوفع  TRI\\n  0.901   \n",
      "41572                                           هيا ينظا  TRI\\n  0.674   \n",
      "41573                          كاعم تيقالت ينا ناحرف ريخ  TRI\\n  0.999   \n",
      "41574                   كلضف نم ويكوط يل هطنشلا نحشن يبن  TRI\\n  0.993   \n",
      "41575                         هيوش ربكا دحاو ينيروت ردقت  TRI\\n  0.564   \n",
      "41576       ريخ تاطيخم نابايلا يف تاعونصملا جياوحلا ينظا  TRI\\n  0.999   \n",
      "41577                                فقوت كنا كلنسحا ناك  TRI\\n  0.970   \n",
      "41578          تحمس ول نوفلتلا مقر و ناونعلا يلبتكت ردقت  TRI\\n  0.909   \n",
      "41579                                               نخسم  TRI\\n  0.196   \n",
      "41580                              هنم يشام ينا راطم اما  TRI\\n  0.980   \n",
      "41581                        هرايطلا يف جذومنلا شكوطع ام  TRI\\n  0.999   \n",
      "41582                                           هوكم يبن  TRI\\n  0.225   \n",
      "41583           هزيمملا مكراكفاب انيل مكتكراشم يلع وتيحص  TRI\\n  0.999   \n",
      "41584       جلزتلا مسوم يف رهشلا يف نيترم جلزتن يشمن ينا  TRI\\n  0.999   \n",
      "41585  نيسمخ و هسمخو هيمعست و فلا هنس ليربا لوا تبجنا...  TRI\\n  0.999   \n",
      "41586          دالبلا طسول عفري يلا طوبضملا صابلا اده له  TRI\\n  0.999   \n",
      "41587                                  يداه هحيرلا شادقب  TRI\\n  0.997   \n",
      "41588                                            ينيش يل  TRI\\n  0.607   \n",
      "41589                    هيمسرلا تاءارجالل يشمن ردقن نيو  TRI\\n  0.555   \n",
      "41590                            فاعسا هرايس ملك كلضف نم  TRI\\n  0.998   \n",
      "41591                                           هياج فيك  TRI\\n  0.339   \n",
      "41592                              شاهبحن ام هلكام شيفام  TRI\\n  0.999   \n",
      "41593  يلاحلا ينابايلا روتسدلا سيسات يركذب لافتحالل ه...  TRI\\n  0.999   \n",
      "41594          زريس جرب يل هرايز لمشت هيحايسلا هلوجلا له  TRI\\n  0.993   \n",
      "41595                         ايانه نم هبيرق هبتكم يف له  TRI\\n  0.999   \n",
      "41596                 ياواه هعماج يف هفيص هسردم شخنب ينا  TRI\\n  0.999   \n",
      "41597                              اوت ينح نيمطاخ نيو نم  TRI\\n  0.999   \n",
      "41598                          نينس هتالت ليع و رابك زوز  TRI\\n  0.999   \n",
      "41599                                  هطحملا يف مامح يف  TRI\\n  0.961   \n",
      "\n",
      "          model  \n",
      "0      msa-char  \n",
      "1      msa-char  \n",
      "2      msa-char  \n",
      "3      msa-char  \n",
      "4      msa-char  \n",
      "5      msa-char  \n",
      "6      msa-char  \n",
      "7      msa-char  \n",
      "8      msa-char  \n",
      "9      jed-char  \n",
      "10     msa-char  \n",
      "11     msa-char  \n",
      "12     msa-char  \n",
      "13     msa-char  \n",
      "14     msa-char  \n",
      "15     msa-char  \n",
      "16     msa-char  \n",
      "17     msa-char  \n",
      "18     msa-char  \n",
      "19     riy-char  \n",
      "20     msa-char  \n",
      "21     msa-char  \n",
      "22     msa-char  \n",
      "23     msa-char  \n",
      "24     msa-char  \n",
      "25     msa-char  \n",
      "26     msa-char  \n",
      "27     riy-char  \n",
      "28     msa-char  \n",
      "29     msa-char  \n",
      "...         ...  \n",
      "41570  tri-char  \n",
      "41571  ben-char  \n",
      "41572  msa-char  \n",
      "41573  tri-char  \n",
      "41574  tri-char  \n",
      "41575  tri-char  \n",
      "41576  tri-char  \n",
      "41577  tri-char  \n",
      "41578  jer-char  \n",
      "41579  tun-char  \n",
      "41580  tri-char  \n",
      "41581  tri-char  \n",
      "41582  asw-char  \n",
      "41583  tri-char  \n",
      "41584  tri-char  \n",
      "41585  tri-char  \n",
      "41586  tri-char  \n",
      "41587  tri-char  \n",
      "41588  tri-char  \n",
      "41589  ben-char  \n",
      "41590  tri-char  \n",
      "41591  doh-char  \n",
      "41592  tri-char  \n",
      "41593  tri-char  \n",
      "41594  tri-char  \n",
      "41595  tri-char  \n",
      "41596  tri-char  \n",
      "41597  tri-char  \n",
      "41598  tri-char  \n",
      "41599  doh-char  \n",
      "\n",
      "[41600 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
